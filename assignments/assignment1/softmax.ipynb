{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from past.builtins import xrange\n",
    "\n",
    "def softmax_loss_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Softmax loss function, naive implementation (with loops)\n",
    "    \n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - reg: (float) regularization strength\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    # Initialize the loss and gradient to zero.\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    #############################################################################\n",
    "    # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
    "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
    "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
    "    # regularization!                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    \n",
    "    for i in xrange(num_train):\n",
    "    \n",
    "        # loss\n",
    "        scores = X[i] @ W\n",
    "        # shift values for 'scores' for numeric reasons (over-flow cautious)\n",
    "        \n",
    "        # Get corresponding values for each score.\n",
    "        scores -= scores.max()\n",
    "        scores_expsum = np.sum(np.exp(scores))\n",
    "        cor_ex = np.exp(scores[y[i]])\n",
    "        \n",
    "        # Final softmax equation.\n",
    "        loss += - np.log( cor_ex / scores_expsum)\n",
    "    \n",
    "        # grad\n",
    "        # for correct class\n",
    "        dW[:, y[i]] += (-1) * (scores_expsum - cor_ex) / scores_expsum * X[i]\n",
    "        \n",
    "        for j in xrange(num_classes):\n",
    "            # pass correct class gradient\n",
    "            if j == y[i]:\n",
    "                continue\n",
    "            # for incorrect classes\n",
    "            dW[:, j] += np.exp(scores[j]) / scores_expsum * X[i]\n",
    "    \n",
    "    loss /= num_train\n",
    "    loss += reg * np.sum(W * W)\n",
    "    dW /= num_train\n",
    "    dW += 2 * reg * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                          END OF YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    return loss, dW\n",
    "    \n",
    "    \n",
    "def softmax_loss_vectorized(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Softmax loss function, vectorized version.\n",
    "    Inputs and outputs are the same as softmax_loss_naive.\n",
    "    \"\"\"\n",
    "    # Initialize the loss and gradient to zero.\n",
    "    N = X.shape[0]\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    #print('N = {}'.format(N))\n",
    "    #print('loss = {}'.format(loss))\n",
    "    #print('dW = {}'.format(dW))\n",
    "    \n",
    "    #############################################################################\n",
    "    # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
    "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
    "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
    "    # regularization!                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    # forward\n",
    "    score = X @ W # (N, C)\n",
    "    #print('score = {}'.format(score))\n",
    "    out = np.exp(score)\n",
    "    #print('out before = {}'.format(out))\n",
    "    out /= np.sum(out, axis=1, keepdims=True)   # (N, C)\n",
    "    #print('out after = {}'.format(out))\n",
    "    loss -= np.sum(np.log(out[np.arange(N), y]))\n",
    "    #print('loss 1 = {}'.format(loss))\n",
    "    loss /= N\n",
    "    #print('loss 2 = {}'.format(loss))\n",
    "    loss += (1/2) * reg * np.sum(W**2)\n",
    "    #print('loss 3 = {}'.format(loss))\n",
    "    \n",
    "    # backward\n",
    "    d_out = np.copy(out)   # (N, C)\n",
    "    d_out[np.arange(N), y] -= 1\n",
    "    dW = X.T @ d_out # (D, C)\n",
    "    dW /= N\n",
    "    dW += reg * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                          END OF YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "#from cs231n.classifiers.linear_svm import *\n",
    "#from cs231n.classifiers.softmax import *\n",
    "from past.builtins import xrange\n",
    "\n",
    "\n",
    "class LinearClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "              batch_size=128, verbose=False):\n",
    "        \"\"\"\n",
    "        Train this linear classifier using stochastic gradient descent.\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "          training samples each of dimension D.\n",
    "        - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
    "          means that X[i] has label 0 <= c < C for C classes.\n",
    "        - learning_rate: (float) learning rate for optimization.\n",
    "        - reg: (float) regularization strength.\n",
    "        - num_iters: (integer) number of steps to take when optimizing\n",
    "        - batch_size: (integer) number of training examples to use at each step.\n",
    "        - verbose: (boolean) If true, print progress during optimization.\n",
    "        Outputs:\n",
    "        A list containing the value of the loss function at each training iteration.\n",
    "        \"\"\"\n",
    "        num_train, dim = X.shape\n",
    "        num_classes = np.max(y) + 1  # assume y takes values 0...K-1 where K is number of classes\n",
    "        \n",
    "        if self.W is None:\n",
    "            # lazily initialize W\n",
    "            self.W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        \n",
    "        for it in xrange(num_iters):\n",
    "            # X_batch = None\n",
    "            # y_batch = None\n",
    "\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Sample batch_size elements from the training data and their           #\n",
    "            # corresponding labels to use in this round of gradient descent.        #\n",
    "            # Store the data in X_batch and their corresponding labels in           #\n",
    "            # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
    "            # and y_batch should have shape (batch_size,)                           #\n",
    "            #                                                                       #\n",
    "            # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
    "            # replacement is faster than sampling without replacement.              #\n",
    "            #########################################################################\n",
    "\n",
    "            # randomize indices\n",
    "            batch_ind = np.random.choice(num_train, batch_size)\n",
    "            X_batch = X[batch_ind]\n",
    "            y_batch = y[batch_ind]\n",
    "\n",
    "            #########################################################################\n",
    "            #                       END OF YOUR CODE                                #\n",
    "            #########################################################################\n",
    "\n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = self.loss(X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            # perform parameter update\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Update the weights using the gradient and the learning rate.          #\n",
    "            #########################################################################\n",
    "\n",
    "            self.W += - learning_rate * grad\n",
    "\n",
    "            #########################################################################\n",
    "            #                       END OF YOUR CODE                                #\n",
    "            #########################################################################\n",
    "\n",
    "            if verbose and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained weights of this linear classifier to predict labels for\n",
    "        data points.\n",
    "    \n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "          training samples each of dimension D.\n",
    "    \n",
    "        Returns:\n",
    "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
    "          array of length N, and each element is an integer giving the predicted\n",
    "          class.\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        ###########################################################################\n",
    "        # TODO:                                                                   #\n",
    "        # Implement this method. Store the predicted labels in y_pred.            #\n",
    "        ###########################################################################\n",
    "        \n",
    "        scores = X @ self.W\n",
    "        y_pred = np.argmax(scores, axis=1)\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "        return y_pred\n",
    "  \n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        \"\"\"\n",
    "        Compute the loss function and its derivative. \n",
    "        Subclasses will override this.\n",
    "    \n",
    "        Inputs:\n",
    "        - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
    "          data points; each point has dimension D.\n",
    "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
    "        - reg: (float) regularization strength.\n",
    "    \n",
    "        Returns: A tuple containing:\n",
    "        - loss as a single float\n",
    "        - gradient with respect to self.W; an array of the same shape as W\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "class LinearSVM(LinearClassifier):\n",
    "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        return svm_loss_vectorized(self.W, X_batch, y_batch, reg)\n",
    "\n",
    "    \n",
    "class Softmax(LinearClassifier):\n",
    "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
    "\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.353029\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "#from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n",
    "\n",
    "We have 10 classes, and we're choosing among one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.403271 analytic: -0.403271, relative error: 2.106350e-07\n",
      "numerical: -4.046508 analytic: -4.046508, relative error: 4.451626e-09\n",
      "numerical: 2.043041 analytic: 2.043041, relative error: 2.623275e-08\n",
      "numerical: 0.847476 analytic: 0.847476, relative error: 4.937798e-08\n",
      "numerical: 1.630477 analytic: 1.630477, relative error: 4.164259e-08\n",
      "numerical: 1.045480 analytic: 1.045480, relative error: 3.132628e-08\n",
      "numerical: 3.441147 analytic: 3.441147, relative error: 1.645802e-08\n",
      "numerical: -1.101988 analytic: -1.101989, relative error: 4.659477e-08\n",
      "numerical: 1.070303 analytic: 1.070303, relative error: 7.036213e-08\n",
      "numerical: 3.735018 analytic: 3.735018, relative error: 3.992906e-09\n",
      "numerical: -0.522507 analytic: -0.522507, relative error: 1.133878e-08\n",
      "numerical: 2.333045 analytic: 2.333045, relative error: 2.033609e-08\n",
      "numerical: -0.193402 analytic: -0.193402, relative error: 1.568157e-07\n",
      "numerical: -4.002122 analytic: -4.002122, relative error: 1.515265e-08\n",
      "numerical: 1.078334 analytic: 1.078334, relative error: 6.699187e-08\n",
      "numerical: 1.869807 analytic: 1.869807, relative error: 2.620556e-09\n",
      "numerical: 0.745679 analytic: 0.745679, relative error: 1.304986e-07\n",
      "numerical: 2.440418 analytic: 2.440418, relative error: 1.205520e-09\n",
      "numerical: -1.466579 analytic: -1.466579, relative error: 2.479930e-09\n",
      "numerical: -0.438905 analytic: -0.438905, relative error: 3.595163e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.353029e+00 computed in 0.091730s\n",
      "vectorized loss: 2.353029e+00 computed in 0.004987s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "#from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.346592 val accuracy: 0.361000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.320469 val accuracy: 0.332000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.349347 val accuracy: 0.349000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.332163 val accuracy: 0.355000\n",
      "best validation accuracy achieved during cross-validation: 0.361000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "\n",
    "#from cs231n.classifiers import Softmax\n",
    "\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        acc_train = np.mean(y_train == y_train_pred)\n",
    "        \n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        acc_val = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = (acc_train, acc_val)\n",
    "        \n",
    "        if acc_val > best_val:\n",
    "            best_val = acc_val\n",
    "            best_softmax = softmax\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.360000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
