{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from past.builtins import xrange\n",
    "\n",
    "def softmax_loss_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Softmax loss function, naive implementation (with loops)\n",
    "    \n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - reg: (float) regularization strength\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    # Initialize the loss and gradient to zero.\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    #############################################################################\n",
    "    # TODO: Compute the softmax loss and its gradient using explicit loops.     #\n",
    "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
    "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
    "    # regularization!                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    \n",
    "    for i in xrange(num_train):\n",
    "    \n",
    "        # loss\n",
    "        scores = X[i].dot(W)\n",
    "        # shift values for 'scores' for numeric reasons (over-flow cautious)\n",
    "        scores -= scores.max()\n",
    "        scores_expsum = np.sum(np.exp(scores))\n",
    "        cor_ex = np.exp(scores[y[i]])\n",
    "        loss += - np.log( cor_ex / scores_expsum)\n",
    "    \n",
    "        # grad\n",
    "        # for correct class\n",
    "        dW[:, y[i]] += (-1) * (scores_expsum - cor_ex) / scores_expsum * X[i]\n",
    "        \n",
    "        for j in xrange(num_classes):\n",
    "            # pass correct class gradient\n",
    "            if j == y[i]:\n",
    "                continue\n",
    "            # for incorrect classes\n",
    "            dW[:, j] += np.exp(scores[j]) / scores_expsum * X[i]\n",
    "    \n",
    "    loss /= num_train\n",
    "    loss += reg * np.sum(W * W)\n",
    "    dW /= num_train\n",
    "    dW += 2 * reg * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                          END OF YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    return loss, dW\n",
    "    \n",
    "    \n",
    "def softmax_loss_vectorized(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Softmax loss function, vectorized version.\n",
    "    Inputs and outputs are the same as softmax_loss_naive.\n",
    "    \"\"\"\n",
    "    # Initialize the loss and gradient to zero.\n",
    "    N = X.shape[0]\n",
    "    loss = 0.0\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    #print('N = {}'.format(N))\n",
    "    #print('loss = {}'.format(loss))\n",
    "    #print('dW = {}'.format(dW))\n",
    "    \n",
    "    #############################################################################\n",
    "    # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
    "    # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
    "    # here, it is easy to run into numeric instability. Don't forget the        #\n",
    "    # regularization!                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    # forward\n",
    "    score = np.dot(X, W)   # (N, C)\n",
    "    #print('score = {}'.format(score))\n",
    "    out = np.exp(score)\n",
    "    #print('out before = {}'.format(out))\n",
    "    out /= np.sum(out, axis=1, keepdims=True)   # (N, C)\n",
    "    #print('out after = {}'.format(out))\n",
    "    loss -= np.sum(np.log(out[np.arange(N), y]))\n",
    "    #print('loss 1 = {}'.format(loss))\n",
    "    loss /= N\n",
    "    #print('loss 2 = {}'.format(loss))\n",
    "    loss += 0.5 * reg * np.sum(W**2)\n",
    "    #print('loss 3 = {}'.format(loss))\n",
    "    \n",
    "    # backward\n",
    "    dout = np.copy(out)   # (N, C)\n",
    "    dout[np.arange(N), y] -= 1\n",
    "    dW = np.dot(X.T, dout)  # (D, C)\n",
    "    dW /= N\n",
    "    dW += reg * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                          END OF YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "#from cs231n.classifiers.linear_svm import *\n",
    "#from cs231n.classifiers.softmax import *\n",
    "from past.builtins import xrange\n",
    "\n",
    "\n",
    "class LinearClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "              batch_size=128, verbose=False):\n",
    "        \"\"\"\n",
    "    Train this linear classifier using stochastic gradient descent.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "      training samples each of dimension D.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
    "      means that X[i] has label 0 <= c < C for C classes.\n",
    "    - learning_rate: (float) learning rate for optimization.\n",
    "    - reg: (float) regularization strength.\n",
    "    - num_iters: (integer) number of steps to take when optimizing\n",
    "    - batch_size: (integer) number of training examples to use at each step.\n",
    "    - verbose: (boolean) If true, print progress during optimization.\n",
    "    Outputs:\n",
    "    A list containing the value of the loss function at each training iteration.\n",
    "    \"\"\"\n",
    "        num_train, dim = X.shape\n",
    "        num_classes = np.max(y) + 1  # assume y takes values 0...K-1 where K is number of classes\n",
    "        if self.W is None:\n",
    "            # lazily initialize W\n",
    "            self.W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "        # Run stochastic gradient descent to optimize W\n",
    "        loss_history = []\n",
    "        for it in xrange(num_iters):\n",
    "            # X_batch = None\n",
    "            # y_batch = None\n",
    "\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Sample batch_size elements from the training data and their           #\n",
    "            # corresponding labels to use in this round of gradient descent.        #\n",
    "            # Store the data in X_batch and their corresponding labels in           #\n",
    "            # y_batch; after sampling X_batch should have shape (dim, batch_size)   #\n",
    "            # and y_batch should have shape (batch_size,)                           #\n",
    "            #                                                                       #\n",
    "            # Hint: Use np.random.choice to generate indices. Sampling with         #\n",
    "            # replacement is faster than sampling without replacement.              #\n",
    "            #########################################################################\n",
    "\n",
    "            # randomize indices\n",
    "            batch_ind = np.random.choice(num_train, batch_size)\n",
    "            X_batch = X[batch_ind]\n",
    "            y_batch = y[batch_ind]\n",
    "\n",
    "            #########################################################################\n",
    "            #                       END OF YOUR CODE                                #\n",
    "            #########################################################################\n",
    "\n",
    "            # evaluate loss and gradient\n",
    "            loss, grad = self.loss(X_batch, y_batch, reg)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            # perform parameter update\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Update the weights using the gradient and the learning rate.          #\n",
    "            #########################################################################\n",
    "\n",
    "            self.W += - learning_rate * grad\n",
    "\n",
    "            #########################################################################\n",
    "            #                       END OF YOUR CODE                                #\n",
    "            #########################################################################\n",
    "\n",
    "            if verbose and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained weights of this linear classifier to predict labels for\n",
    "        data points.\n",
    "    \n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "          training samples each of dimension D.\n",
    "    \n",
    "        Returns:\n",
    "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
    "          array of length N, and each element is an integer giving the predicted\n",
    "          class.\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        ###########################################################################\n",
    "        # TODO:                                                                   #\n",
    "        # Implement this method. Store the predicted labels in y_pred.            #\n",
    "        ###########################################################################\n",
    "        \n",
    "        scores = X @ self.W\n",
    "        y_pred = np.argmax(scores, axis=1)\n",
    "        \n",
    "        ###########################################################################\n",
    "        #                           END OF YOUR CODE                              #\n",
    "        ###########################################################################\n",
    "        return y_pred\n",
    "  \n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        \"\"\"\n",
    "        Compute the loss function and its derivative. \n",
    "        Subclasses will override this.\n",
    "    \n",
    "        Inputs:\n",
    "        - X_batch: A numpy array of shape (N, D) containing a minibatch of N\n",
    "          data points; each point has dimension D.\n",
    "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
    "        - reg: (float) regularization strength.\n",
    "    \n",
    "        Returns: A tuple containing:\n",
    "        - loss as a single float\n",
    "        - gradient with respect to self.W; an array of the same shape as W\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "class LinearSVM(LinearClassifier):\n",
    "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        return svm_loss_vectorized(self.W, X_batch, y_batch, reg)\n",
    "\n",
    "    \n",
    "class Softmax(LinearClassifier):\n",
    "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
    "\n",
    "    def loss(self, X_batch, y_batch, reg):\n",
    "        return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.407957\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "#from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n",
    "\n",
    "We have 10 classes, and we're choosing among one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.153775 analytic: 0.153775, relative error: 6.354525e-08\n",
      "numerical: -0.967290 analytic: -0.967290, relative error: 7.197750e-09\n",
      "numerical: -0.269990 analytic: -0.269990, relative error: 1.274161e-08\n",
      "numerical: -0.092212 analytic: -0.092212, relative error: 6.216153e-08\n",
      "numerical: -0.673988 analytic: -0.673988, relative error: 2.863409e-08\n",
      "numerical: 1.140229 analytic: 1.140228, relative error: 1.750583e-08\n",
      "numerical: -0.795648 analytic: -0.795648, relative error: 2.281361e-08\n",
      "numerical: 0.015306 analytic: 0.015306, relative error: 4.596110e-07\n",
      "numerical: 1.472616 analytic: 1.472616, relative error: 1.568984e-09\n",
      "numerical: 0.574427 analytic: 0.574427, relative error: 1.852564e-08\n",
      "numerical: 2.619279 analytic: 2.619279, relative error: 6.158822e-09\n",
      "numerical: 3.188591 analytic: 3.188591, relative error: 1.185387e-08\n",
      "numerical: 0.413263 analytic: 0.413263, relative error: 1.957530e-08\n",
      "numerical: 0.798858 analytic: 0.798857, relative error: 1.146465e-07\n",
      "numerical: 1.963417 analytic: 1.963417, relative error: 1.053278e-08\n",
      "numerical: 2.945771 analytic: 2.945771, relative error: 3.024517e-09\n",
      "numerical: -1.596036 analytic: -1.596036, relative error: 1.064559e-09\n",
      "numerical: 3.676338 analytic: 3.676338, relative error: 2.355970e-08\n",
      "numerical: -0.747198 analytic: -0.747198, relative error: 7.339974e-08\n",
      "numerical: -1.338832 analytic: -1.338832, relative error: 1.678472e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.407957e+00 computed in 0.081753s\n",
      "vectorized loss: 2.407957e+00 computed in 0.002995s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "#from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.348327 val accuracy: 0.363000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.325061 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.343143 val accuracy: 0.356000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.322469 val accuracy: 0.345000\n",
      "best validation accuracy achieved during cross-validation: 0.363000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "\n",
    "#from cs231n.classifiers import Softmax\n",
    "\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        acc_train = np.mean(y_train == y_train_pred)\n",
    "        \n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        acc_val = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = (acc_train, acc_val)\n",
    "        \n",
    "        if acc_val > best_val:\n",
    "            best_val = acc_val\n",
    "            best_softmax = softmax\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.333000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
